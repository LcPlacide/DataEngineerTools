{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitdataengineertoolspipenvf1548bae990c4f75be7b0e4d604e2c09",
   "display_name": "Python 3.8.5 64-bit ('DataEngineerTools': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1- Web Scraping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "class Scrapper:\n",
    "    def __init__(self,url):\n",
    "        self.userAgentsList =[\n",
    "            'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.5; fr; rv:1.9.0.3) Gecko/2008092414 Firefox/3.0.3',\n",
    "            'Mozilla/5.0 (X11; U; Linux i686; fr; rv:1.9.1.1) Gecko/20090715 Firefox/3.5.1',\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.110 Safari/537.36',\n",
    "            'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)']\n",
    "        self.headers={'User_Agent':random.choice(self.userAgentsList)} # Part 1 Exercice 3\n",
    "        self.url=url\n",
    "\n",
    "    # Part 1 Exercice 1:\n",
    "    def get_response(self,timeout=10,max_retry=3):\n",
    "        lastException =None\n",
    "        for i in range(max_retry):\n",
    "            try:\n",
    "                response = requests.get(self.url,headers=self.headers,timeout=timeout)\n",
    "                return response.text\n",
    "            except Exception as e:\n",
    "                lastException=e\n",
    "        raise lastException\n",
    "\n",
    "    # Part 1 Exercice 2\n",
    "    def remove_white_spaces(self,x):\n",
    "        return x.strip()\n",
    "\n",
    "    def clean_html_string(self,raw_html):\n",
    "        cleanr = re.compile('<.*?>||&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "        cleantext = re.sub(cleanr,'',raw_html)\n",
    "        return cleantext\n",
    "\n",
    "    def extract_domain_name(self):\n",
    "        m=re.search('https?://([A_Za-z_0-9.-]+).*',self.url)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "\n",
    "    # Part 1 Exercice 3\n",
    "    def get_soup(self,text_response):\n",
    "        soup=BeautifulSoup(text_response,\"lxml\")\n",
    "        return soup\n",
    "\n",
    "    def get_title(self,soup):\n",
    "        return soup.find(\"title\").text\n",
    "\n",
    "    def get_all_h1(self,soup):\n",
    "        return [elt.txt for elt in soup.findAll('h2')]\n",
    "    \n",
    "    def tag_visible(self,element):\n",
    "        if element.parent.name in ['style','script','head', 'title', 'meta', \"|document|\"]:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def get_main_text(self,soup):\n",
    "        texts = soup.findAll(text=True)\n",
    "        visible_texts = filter(self.tag_visible, texts)\n",
    "        return ' '.join(t.strip() for t in visible_texts)\n",
    "\n",
    "    def get_out_links(self,soup):\n",
    "        links_list= [elmt['href'] for elt in soup.findAll('a')]\n",
    "\n",
    "\n",
    "    # Visualisation des résultats\n",
    "    def main(self,s=0,f=1000):\n",
    "        response= self.get_response()\n",
    "        rep_white_spaces='>'.join(self.remove_white_spaces(x) for x in response.split())\n",
    "        clean_rep=self.clean_html_string(rep_white_spaces)\n",
    "        soup = self.get_soup(response)\n",
    "        res={'url':self.url,\n",
    "\n",
    "            'response':response[s:f],\n",
    "\n",
    "            'rep_white_spaces':rep_white_spaces[s:f],\n",
    "            'clean_rep': clean_rep[s:f],\n",
    "            'domain_name': self.extract_domain_name(),\n",
    "            \n",
    "            'soup':soup,\n",
    "            'UserAgent':self.headers,\n",
    "            'title':self.get_title(soup),\n",
    "            'h2':self.get_all_h1(soup),\n",
    "            'main_text':self.get_main_text(soup)[s:f],\n",
    "            \n",
    "        }\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'html [if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif] [if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif] [if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif] [if IE 9]>         <html class=\"no-js ie9\"> <![endif] [if gt IE 9]><!  <![endif]    Google Tag Manager (noscript)   End Google Tag Manager (noscript)                  Les outils ESIEE Paris  Webmail ESIEE Paris  Emploi du temps général  Emploi du temps individuel  Extranet  iCampus  Microsoft DreamSpark                                                 menu  Formations    RETOUR menu  Formations ESIEE Paris Ingénieur    Ingénieur  RETOUR Formations  Ingénieur ESIEE Paris Premier cycle Le cycle ingénieur    Le cycle ingénieur  RETOUR Ingénieur  Le cycle ingénieur ESIEE Paris Enseignements de 1ère année Enseignements de 2e et 3e année Profils métiers Filières    Filières  RETOUR Ingénieur  9 filières, 1 diplôme Informatique Cybersécurité Datascience et intelligence artificielle Artificial Intelli'"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "source": [
    "url = \"http://www.esiee.fr/\"\n",
    "s=Scrapper(url)\n",
    "#print(s.get_response())\n",
    "result=s.main()\n",
    "result[\"main_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-86209c2fa720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https?:([A_Za-z_0-9.-]+).*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "re.search('https?:([A_Za-z_0-9.-]+).*',url).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}